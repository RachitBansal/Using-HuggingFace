# Using HuggingFace

This repository contains notebook links, data and other additonal resources as used in the HuggingFace tutorials on [MLNerdie Delhi's YouTube Channel](https://www.youtube.com/channel/UC8idbgyVu0s3GzayaSbAs9w)

Feel free to play around the ipynb notebooks in Google Colaboratory (by clicking the 'Open in Colab' link on the top of the notebook)

## List of videos:

- [YouTube/Tutorial-1](https://youtu.be/B5M_F9dYHOM) consists of experimenting with 'straight out-of-the-box' functionalities of HuggingFace Transformers, without using any data, training, pre-traing or fine-tuning of any sorts. It mostly represents the wide range of tasks for which Tranformers can be used and their precision in doing so.  


## Additional Links and References:

- [HuggingFace](https://github.com/huggingface)

- [OpenAI/GPT-2](https://openai.com/blog/better-language-models/)

- [BART Paper](https://arxiv.org/abs/1910.13461)

- [Curious Case of Neural Text Degeneration](https://arxiv.org/abs/1904.09751)
